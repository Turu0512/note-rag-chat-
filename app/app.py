# app.py

import os
import json
import requests
import streamlit as st
import chromadb
from sentence_transformers import SentenceTransformer

# â”€â”€ ç’°å¢ƒå¤‰æ•° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
PERSIST_DIR = os.environ.get("CHROMA_PERSIST_DIR", "./chroma_db")
COLLECTION  = os.environ.get("CHROMA_COLLECTION", "note_articles")
EMBED_MODEL = os.environ.get("EMBED_MODEL", "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2")
API_URL     = os.environ.get("NOTE_RAG_API_URL", "http://localhost:8000/query")  # FastAPI /query

# â”€â”€ ã‚­ãƒ£ãƒƒã‚·ãƒ¥åŒ–ï¼ˆèµ·å‹•é«˜é€ŸåŒ–ï¼‰ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@st.cache_resource
def get_collection():
    client = chromadb.PersistentClient(path=PERSIST_DIR)
    return client.get_collection(COLLECTION)

@st.cache_resource
def get_embedder():
    return SentenceTransformer(EMBED_MODEL)

col = get_collection()
embedder = get_embedder()

# â”€â”€ UI â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.title("Noteè¨˜äº‹æ¤œç´¢Bot")

tab_llm, tab_vector = st.tabs(["ğŸ’¬ LLMå›ç­”ï¼ˆ/query ä½¿ç”¨ï¼‰", "ğŸ” ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ï¼ˆãƒ­ãƒ¼ã‚«ãƒ«ï¼‰"])

with tab_llm:
    st.caption("FastAPI ã® /query ã‚’å‘¼ã³å‡ºã—ã¦ã€æ§‹é€ åŒ–JSONï¼ˆsummary, pointsï¼‰ã§å›ç­”ã—ã¾ã™ã€‚")
    q = st.text_input("çŸ¥ã‚ŠãŸã„ã“ã¨ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ï¼ˆLLMï¼‰", key="llm_q")
    display_mode = st.radio("è¡¨ç¤ºãƒ¢ãƒ¼ãƒ‰", ["Markdown", "ãƒ—ãƒ¬ãƒ¼ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ"], horizontal=True)

    if q:
        try:
            resp = requests.post(API_URL, json={"question": q}, timeout=60)
            if resp.status_code != 200:
                st.error(f"APIã‚¨ãƒ©ãƒ¼: {resp.status_code} - {resp.text}")
            else:
                data = resp.json()
                summary = data.get("summary", "")
                points  = data.get("points", [])

                if display_mode == "Markdown":
                    st.markdown("### è¦ç´„")
                    st.markdown(summary)
                    if points:
                        st.markdown("### é‡è¦ãƒã‚¤ãƒ³ãƒˆ")
                        st.markdown("\n".join([f"- {p}" for p in points]))
                else:
                    st.write("è¦ç´„")
                    st.write(summary)
                    if points:
                        st.write("é‡è¦ãƒã‚¤ãƒ³ãƒˆ")
                        for p in points:
                            st.write(f"ãƒ»{p}")
        except Exception as e:
            st.exception(e)

with tab_vector:
    st.caption("ChromaDBã¸ç›´æ¥ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ã—ã¾ã™ï¼ˆLLMã«ã¯æŠ•ã’ã¾ã›ã‚“ï¼‰ã€‚")
    q2 = st.text_input("æ¤œç´¢ã—ãŸã„å†…å®¹ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ï¼ˆãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ï¼‰", key="vec_q")
    topk = st.slider("ä»¶æ•°", 1, 10, 3)
    if q2:
        q_emb = embedder.encode([q2])[0].tolist()
        res = col.query(query_embeddings=[q_emb], n_results=topk)
        docs   = (res.get("documents") or [[]])[0]
        metas  = (res.get("metadatas") or [[]])[0]

        for i, (doc, meta) in enumerate(zip(docs, metas), start=1):
            st.write(f"### [{i}] {meta.get('filename','(no name)')}")
            st.text(doc[:1000])
